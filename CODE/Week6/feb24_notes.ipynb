{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brown\">Regular Expressions - Continued</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Verbose, multiline regexp</font>\n",
    "Suppose we want to do some capturing in an address of the form<br>\n",
    "`<optional #><apt num><whitespace><street name>,<city>,<2 character upper case state code><whitespace><zip>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        (\\d+)           # capture apt number\n",
    "        \\s+             # at least one white space \n",
    "        (.*)?,          # capture street name, non-greedy sequence until ',', \n",
    "        \\s*             # possible whitespace\n",
    "        (.*)?,          # capture city name, non-greedy sequence until ',', \n",
    "        \\s*             # possible white space\n",
    "        ([A-Z]{2})      # capture state code\n",
    "        \\s*             # possible white space\n",
    "        (\\d{5})         # capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Infinite Loop\n",
      "Cupertino\n",
      "CA\n",
      "12345\n"
     ]
    }
   ],
   "source": [
    "res = addr.match(' # 25 Infinite Loop,Cupertino,CA 12345')\n",
    "if res:\n",
    "    for gr in res.groups():\n",
    "        print(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Infinite Loop\n",
      "Cupertino \n",
      "CA\n",
      "12345\n"
     ]
    }
   ],
   "source": [
    "res = addr.match('#25 Infinite Loop,  Cupertino , CA 12345')\n",
    "if res:\n",
    "    for gr in res.groups():\n",
    "        print(gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Naming captured fields</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can give names to the captured fields for easier access, using ?P in group\n",
    "named_addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        (?P<apt>\\d+)    # capture apt number\n",
    "        \\s+             # at least one white space \n",
    "        (?P<street>.*)?, # capture street name, non-greedy sequence until ',', \n",
    "        \\s*             # possible whitespace\n",
    "        (?P<city>.*)?,  # capture city name, non-greedy sequence until ',', \n",
    "        \\s*             # possible white space\n",
    "        (?P<state>[A-Z]{2})      # capture state code\n",
    "        \\s*             # possible white space\n",
    "        (?P<zip>\\d{5})  # capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apt': '10',\n",
       " 'street': 'California Avenue',\n",
       " 'city': 'Palo Alto',\n",
       " 'state': 'CA',\n",
       " 'zip': '94304'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = named_addr.match(' # 10 California Avenue,Palo Alto,CA 94304')\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Suppressing captures</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can suppress capture using ?: inside group\n",
    "named_addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        (?:\\d+)         # don't capture apt num\n",
    "        \\s+             # at least one white space \n",
    "        (?:.*)?,        # don't capture street \n",
    "        \\s*             # possible whitespace\n",
    "        (?P<city>.*)?,  # capture city name, name it as 'city'\n",
    "        \\s*             # possible white space\n",
    "        (?P<state>[A-Z]{2})      # capture state code, name it as 'state'\n",
    "        \\s*             # possible white space\n",
    "        (?:\\d{5})       # don't capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Palo Alto', 'state': 'CA'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = named_addr.match(' #10 California Avenue,Palo Alto,CA 94304')\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can, of course, get rid of the () for capture altogether** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can suppress capture using ?: inside group\n",
    "named_addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        \\d+             # don't capture apt num\n",
    "        \\s+             # at least one white space \n",
    "        .*?,            # don't capture street \n",
    "        \\s*             # possible whitespace\n",
    "        (?P<city>.*)?,  # capture city name, name it as 'city'\n",
    "        \\s*             # possible white space\n",
    "        (?P<state>[A-Z]{2})      # capture state code, name it as 'state'\n",
    "        \\s*             # possible white space\n",
    "        \\d{5}           # don't capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Palo Alto', 'state': 'CA'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = named_addr.match(' #10 California Avenue,Palo Alto,CA 94304')\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But the reason you may want to keep them is you can then turn captures on and off as needed** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Back referencing captures using name</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 19), match='air or hot air'>\n"
     ]
    }
   ],
   "source": [
    "# Captured string can be back referenced\n",
    "backref = re.compile(r\"\"\"\n",
    "            (?P<air>air)     # capture the string 'air', name it as 'air'\n",
    "            .*               # greedy\n",
    "            (?P=air)         # capture backrefernce to previous name 'air'\n",
    "            \"\"\", re.VERBOSE)\n",
    "res = backref.search('cool air or hot air')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 19), match='air or hot air'>\n"
     ]
    }
   ],
   "source": [
    "res = backref.search('cool air or hot air')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "res = backref.search('cool air or hot')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Using findall and finditer functions to get all matches</font>\n",
    "- findall constructs the entire list of matches before returning it\n",
    "- finditer returns one match at a time, on demand, in a Match object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"brown\">findall()</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['These', 'are', 'the', 'days', 'of', 'miracles', 'and', 'wonders']\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "res = re.findall(r'\\w+','These are the days of miracles and wonders!')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'can', 't', 'believe', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Example 2-a\n",
    "res = re.findall(r'\\w+',\"I can't believe it\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"can't\", 'believe', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Example 2-b\n",
    "res = re.findall(r'\\S+',\"I can't believe it\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"brown\">finditer()</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x7fdd685e9d90>\n",
      "These @ (0, 5)\n",
      "are @ (6, 9)\n",
      "the @ (10, 13)\n",
      "days @ (14, 18)\n",
      "of @ (19, 21)\n",
      "miracles @ (22, 30)\n",
      "and @ (31, 34)\n",
      "wonders @ (35, 42)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "iterator = re.finditer(r'\\w+','These are the days of miracles and wonders!')\n",
    "print(iterator)\n",
    "for match in iterator:\n",
    "    print(match.group(),'@',match.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I @ (0, 1)\n",
      "can't @ (2, 7)\n",
      "believe @ (8, 15)\n",
      "it @ (16, 18)\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "iterator = re.finditer(r'\\S+',\"I can't believe it\")\n",
    "for match in iterator:\n",
    "    print(match.group(),'@',match.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brown\">Working with Plain Text and CSV Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: UCI Auto MPG dataset - Plain Text File\n",
    "\n",
    "In the text file auto-mpg-original.txt there are several fields in each line. \n",
    "Of these we want the mpg (first field), cylinders (second field),\n",
    "the model year (third to last), and car name (last). \n",
    "We want to read lines from this file, and write these \n",
    "fields out in the following format:\n",
    "<pre>\n",
    "\"car name\",year (19xx),cylinders (int),mpg\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 1: Using Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str='18.0   8.   307.0      130.0      3504.      12.0   70.  1.\t\"chevrolet chevelle malibu\"'\n",
    "\n",
    "car_reg = re.compile(r\"\"\"\n",
    "                \\s*                    # skip over leading whitespaces, if any\n",
    "                (?P<mpg>\\d{2}\\.\\d)     # mpg field is of the form dd.d\n",
    "                \\s*                    # skip white spaces\n",
    "                (?P<cyl>\\d)\\.          # cylinders field is of the form d., only want d\n",
    "                .*                     # skip all intervening stuff\n",
    "                (?P<yy>\\d{2})\\.        # year is of form dd., only want dd\n",
    "                \\s*                    # skip whitespaces\n",
    "                \\d\\.                   # origin is of the form d.\n",
    "                .*                     # skip intervening stuff\n",
    "                (?P<name>\".*\")         # car name is in double quotes, want double quotes\n",
    "            \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpg': '18.0', 'cyl': '8', 'yy': '70', 'name': '\"chevrolet chevelle malibu\"'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = car_reg.match(test_str)\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chevrolet chevelle malibu\",1970,8,18.0\n"
     ]
    }
   ],
   "source": [
    "res = car_reg.match(test_str)\n",
    "if res:\n",
    "    car_dict = res.groupdict()\n",
    "    keys = ['name','yy','cyl','mpg']\n",
    "    values = [car_dict[k] for k in keys]\n",
    "    values[1] = '19' + values[1]\n",
    "    print(','.join(values))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice the string join method above<br>\n",
    "Iterable for join must have string values, otherwise won't work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print a few lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(in_line):\n",
    "    res = car_reg.match(in_line)\n",
    "    if res:\n",
    "        car_dict = res.groupdict()\n",
    "        keys = ['name','yy','cyl','mpg']\n",
    "        values = [car_dict[k] for k in keys]\n",
    "        values[1] = '19' + values[1]\n",
    "        return ','.join(values) \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chevrolet chevelle malibu\",1970,8,18.0\n",
      "\"buick skylark 320\",1970,8,15.0\n",
      "\"plymouth satellite\",1970,8,18.0\n",
      "\"amc rebel sst\",1970,8,16.0\n",
      "\"ford torino\",1970,8,17.0\n",
      "\"ford galaxie 500\",1970,8,15.0\n",
      "\"chevrolet impala\",1970,8,14.0\n",
      "\"plymouth fury iii\",1970,8,14.0\n",
      "\"pontiac catalina\",1970,8,14.0\n",
      "\"amc ambassador dpl\",1970,8,15.0\n",
      "\"dodge challenger se\",1970,8,15.0\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    out_line = my_filter(line)\n",
    "    if out_line:\n",
    "        print(my_filter(line))\n",
    "    if i > 14:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The 5 lines immediately before that for \"dodge challenger se\" in the file are rejected because the first field '(NA)' doesn't meet the regular expression requirement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2: Using String split\n",
    "**This alternative wasn't covered in class, but it's based on material we have covered before in basic Python, so I am leaving this as an exercise for you to go over.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0,8,1970,\"chevrolet\n",
      "15.0,8,1970,\"buick\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    flds = line.split()  # on white space\n",
    "    out_flds = []\n",
    "    out_flds.append(flds[0])\n",
    "    out_flds.append(flds[1][:-1])\n",
    "    out_flds.append('19' + flds[6][:-1])\n",
    "    out_flds.append(flds[8])\n",
    "    print(','.join(out_flds))\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hmm, the car name gets truncated because it's got a space in it, and split will break it up into parts. Sow do we address this? We could simply grab all the remainging fields at the end, and concatenate them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 3: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ca3ec5afcb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mout_flds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'19'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mout_flds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_flds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 3: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    flds = line.split()  # on white space\n",
    "    out_flds = []\n",
    "    out_flds.append(flds[0])\n",
    "    out_flds.append(flds[1][:-1])\n",
    "    out_flds.append('19' + flds[6][:-1])\n",
    "    out_flds.append(flds[8:])\n",
    "    print(','.join(out_flds))\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above, join is expected strings in the iterable, but finds a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"chevrolet', 'chevelle', 'malibu\"']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flds = line.split()  # on white space\n",
    "out_flds = []\n",
    "out_flds.append(flds[8:])\n",
    "out_flds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The car name parts are broken up and gathered into a list. We don't want a list, instead we want a single string out of the parts. We can get this by joining the list items around a space.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"chevrolet chevelle malibu\"']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_flds = []\n",
    "out_flds.append(' '.join(flds[8:]))\n",
    "out_flds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0,8,1970,\"chevrolet chevelle malibu\"\n",
      "15.0,8,1970,\"buick skylark 320\"\n"
     ]
    }
   ],
   "source": [
    "# need to join the flds[8:] list items using a space\n",
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    flds = line.split()  # on white space\n",
    "    out_flds = []\n",
    "    out_flds.append(flds[0])\n",
    "    out_flds.append(flds[1][:-1])\n",
    "    out_flds.append('19' + flds[6][:-1])\n",
    "    out_flds.append(' '.join(flds[8:]))\n",
    "    print(','.join(out_flds))\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">So why use regexp instead of string split?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If fields are missing, or incorrectly formatted, much easier with regexp because you specify exact formats for all fields. With split, you will need to read, then check if there are required number of fields, then check each accepted field for correctness of type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: UCI Iris Dataset - CSV File\n",
    "\n",
    "This file (*iris-messy.csv*) has 5 columns (fields): sepal_length, sepal_width, petal_length, petal_width, iris_type\n",
    "\n",
    "I have deliberately introduced errors in the dataset so you get a feel for what kinds of errors you might generally expect, and how to take corrective action. \n",
    "\n",
    "These are some of the kinds of errors you might see in datasets in general:\n",
    "- Too many fields\n",
    "- Too few fields\n",
    "- Missing value for field\n",
    "- Unknown value (e.g. ?,NA instead of actual value)\n",
    "- Non-numeric value when numeric is expected\n",
    "\n",
    "Other errors are possible (such as outlier values), and we will tackle some of then when we study the Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import the csv module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Make sure there are exactly 5 fields in each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009 >>> ['4.4', '2', '9', '1.4', '0.2', 'Iris-setosa']\n",
      "064 >>> ['6.1', '4.7', '1.4', 'Iris-versicolor']\n",
      "078 >>> ['6.7', '3.0', '4.5', '1.7', '6.5', 'Iris-versicolor']\n",
      "103 >>> ['7', '1', '3.0', '5.9', '2.1', 'Iris-virginica']\n",
      "113 >>> ['6.8', '3.0', '5.5', '2.1']\n",
      "152 >>> []\n"
     ]
    }
   ],
   "source": [
    "with open('iris-messy.csv') as irisfile:      # using the with statement\n",
    "    \n",
    "    reader = csv.reader(irisfile)             # set up CSV reader from file\n",
    "    \n",
    "    next(reader)                              # skip first line of column (field) names\n",
    "    \n",
    "    for num,row in enumerate(reader):         # row will be a list of all column (field) values\n",
    "        if len(row) != 5:                     # lines that have too many or too few columns (fields)\n",
    "            print(f'{(num+1):03} >>> {row}')  # pad row number with leading zeros as needed for 3 digits width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Make sure all fields except last are real numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 009: Too many fields\n",
      "\t ['4.4', '2', '9', '1.4', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 013: Non-numeric value 'N/A'\n",
      "\t ['4.8', 'N/A', '1.4', '0.1', 'Iris-setosa'] \n",
      "\n",
      "Row 035: Non-numeric value 'n/a'\n",
      "\t ['4.9', '3.1', 'n/a', '0.1', 'Iris-setosa'] \n",
      "\n",
      "Row 036: Non-numeric value 'na'\n",
      "\t ['5.0', 'na', '1.2', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 043: Non-numeric value '?'\n",
      "\t ['?', '3.2', '1.3', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 064: Too few fields\n",
      "\t ['6.1', '4.7', '1.4', 'Iris-versicolor'] \n",
      "\n",
      "Row 070: Non-numeric value 'NA'\n",
      "\t ['5.6', '2.5', '3.9', 'NA', 'Iris-versicolor'] \n",
      "\n",
      "Row 077: Non-numeric value '?'\n",
      "\t ['6.8', '2.8', '?', '1.4', 'Iris-versicolor'] \n",
      "\n",
      "Row 078: Too many fields\n",
      "\t ['6.7', '3.0', '4.5', '1.7', '6.5', 'Iris-versicolor'] \n",
      "\n",
      "Row 103: Too many fields\n",
      "\t ['7', '1', '3.0', '5.9', '2.1', 'Iris-virginica'] \n",
      "\n",
      "Row 113: Too few fields\n",
      "\t ['6.8', '3.0', '5.5', '2.1'] \n",
      "\n",
      "Row 127: Non-numeric value '4x8'\n",
      "\t ['6.2', '2.8', '4x8', '1.8', 'Iris-virginica'] \n",
      "\n",
      "Row 137: Non-numeric value '?'\n",
      "\t ['6.3', '3.4', '5.6', '?', 'Iris-virginica'] \n",
      "\n",
      "Row 148: Non-numeric value ''\n",
      "\t ['', '3.0', '5.2', '2.0', 'Iris-virginica'] \n",
      "\n",
      "Row 152: Too few fields\n",
      "\t [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('iris-messy.csv') as irisfile:\n",
    "    reader = csv.reader(irisfile)\n",
    "    next(reader)                           # skip first line of field names\n",
    "    \n",
    "    for num,row in enumerate(reader):\n",
    "        if len(row) != 5:                  # lines that have too many or too few fields\n",
    "            print(f'Row {(num+1):03}:',end='') \n",
    "            print(' Too few fields') if len(row) < 5 else print(' Too many fields')\n",
    "            print('\\t',row,'\\n')\n",
    "        else:\n",
    "            for val in row[:-1]:           # skip last field\n",
    "                try:\n",
    "                    float(val)\n",
    "                except:\n",
    "                    print(f\"Row {(num+1):03}: Non-numeric value '{val}'\")\n",
    "                    print('\\t',row,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Finalize by writing out acceptable lines:**\n",
    "- Skip lines that have too few or too many fields\n",
    "- Replace non-numeric field with NA (standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BAEKGE~1\\AppData\\Local\\Temp/ipykernel_25656/2224189180.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iris-messy.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mirisfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mirisfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m                \u001b[1;31m# read first line of field names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "with open('iris-better.csv','w') as outfile:\n",
    "    with open('iris-messy.csv') as irisfile:\n",
    "        \n",
    "        reader = csv.reader(irisfile)\n",
    "        \n",
    "        row = next(reader)                # read first line of field names\n",
    "        outfile.write(','.join(row))\n",
    "        outfile.write('\\n')\n",
    "    \n",
    "        for num,row in enumerate(reader):\n",
    "            if len(row) != 5:             # skip lines that have too many or too few fields\n",
    "                continue\n",
    "            \n",
    "            outrow = []\n",
    "            for val in row[:-1]:      # check all fields except last for numeric\n",
    "                try:\n",
    "                    float(val)\n",
    "                    outrow.append(val)\n",
    "                except:\n",
    "                    outrow.append('NA')\n",
    "\n",
    "            outrow.append(row[-1])    # last field, non-numeric string\n",
    "            outfile.write(','.join(outrow))\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, you can use a CSV writer to write out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'writer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BAEKGE~1\\AppData\\Local\\Temp/ipykernel_25656/2182241339.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iris-better.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# note the newline=''(empty new line) parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m          \u001b[1;31m# set outfile column delimiter to comma, which is the default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                          \u001b[1;31m# delimiter comma is default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iris-messy.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mirisfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'writer'"
     ]
    }
   ],
   "source": [
    "with open('iris-better.csv','w',newline='') as csvfile:  # note the newline=''(empty new line) parameter \n",
    "    writer = csvfile.writer(csvfile, delimiter=',')          # set outfile column delimiter to comma, which is the default\n",
    "                                                         # delimiter comma is default \n",
    "   \n",
    "    with open('iris-messy.csv') as irisfile:\n",
    "        \n",
    "        reader = csv.reader(irisfile)\n",
    "        \n",
    "        row = next(reader)                               # first line of column names\n",
    "        writer.writerow(row)                             # use writerow method of writer with list of columns as param #this is header\n",
    "    \n",
    "        for num,row in enumerate(reader):\n",
    "            if len(row) != 5:                            # lines that have too many or too few columns\n",
    "                continue\n",
    "            \n",
    "            outrow = []\n",
    "            for val in row[:-1]:                         # check all fields except last for numeric\n",
    "                try:\n",
    "                    float(val)\n",
    "                    outrow.append(val)\n",
    "                except:\n",
    "                    outrow.append('NA')\n",
    "            outrow.append(row[-1])                      # last field, non-numeric string\n",
    "            writer.writerow(outrow)                     # this is output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
